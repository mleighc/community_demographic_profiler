# ğŸŒ Community Demographic Profiler

## ğŸ“Œ Project Overview
**Title:** Building a Community Demographic Profiler with Public Data
**Goal:** Create an automated data pipeline that pulls demographic, economic, and migration data (e.g., from the U.S. Census, IRS, and BLS) for U.S. ZIP codes and counties. The final output is a Quarto-based, interactive report allowing users to explore communities based on characteristics like age distribution, income levels, net migration, and employment trends.

This project simulates a realistic data engineering and analytics workflow designed for public insight, strategic planning, or relocation support. It demonstrates the integration of multiple open datasets, robust transformation logic, and stakeholder-friendly presentation.

Itâ€™s particularly well aligned with **Analytics Engineering** and **Data Engineering** roles, showcasing:
- API integration and dataset normalization
- Schema design and structured data modeling
- Automated orchestration
- Narrative and interactive data storytelling

## ğŸ§° Tech Stack
- **Python** (`requests`, `pandas`, `SQLAlchemy`, [`census`](https://pypi.org/project/census/))
- **APIs**: U.S. Census Bureau ([`census`](https://pypi.org/project/census/)), IRS migration data, BLS (Bureau of Labor Statistics)
- **Database**: PostgreSQL (Neon.tech) or SQLite (for local prototyping)
- **Quarto**: For interactive HTML report hosted on GitHub Pages
- **Orchestration**: GitHub Actions or local cron jobs

## ğŸ“ Project Structure
```bash
community-demographic-profiler/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ credentials.yaml            # API keys and config params
â”œâ”€â”€ data_raw/
â”‚   â”œâ”€â”€ census_demographics.csv
â”‚   â”œâ”€â”€ irs_migration.csv
â”‚   â””â”€â”€ bls_employment.csv
â”œâ”€â”€ data_clean/
â”‚   â””â”€â”€ combined_profiles.csv
â”œâ”€â”€ db/
â”‚   â””â”€â”€ db_utils.py                 # DB connection and load scripts
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ fetch_census.py
â”‚   â”œâ”€â”€ fetch_irs.py
â”‚   â”œâ”€â”€ fetch_bls.py
â”‚   â”œâ”€â”€ clean_transform.py
â”‚   â””â”€â”€ run_pipeline.py
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ profiling_notes.md         # Data caveats, assumptions
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ community_explorer.qmd     # Quarto report
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_cleaning.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ etl_pipeline.yml       # GitHub Actions
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## âœ… Goals
- Extract demographic and economic data for selected ZIP codes or counties
- Normalize and merge datasets into unified community profiles
- Insert into a structured database for querying
- Build an interactive Quarto report for exploration
- Automate updates using cron or GitHub Actions
- Provide visual and narrative summaries of each area

## ğŸ—“ï¸ Timeline / Phases
1. **Data Source Review**: Select endpoints and variables (e.g., population, income, age)
2. **API Extraction**: Use Python to download data into raw files
3. **Data Cleaning + Transformation**: Join, normalize, derive new fields (e.g., age bands)
4. **Database Setup**: Create schema and load pipeline
5. **Interface Development**: Build report with summary tables, charts, and location filters
6. **Automation**: GitHub Actions or cron for scheduled data refreshes
7. **Publishing**: Host Quarto report via GitHub Pages and document key findings

## ğŸ“‹ Project Board

### ğŸ”¨ In Progress
- [ ] Research and select datasets (Census, IRS, BLS)
- [ ] Define database schema and key variables
- [ ] Draft fetch scripts for one data source

### ğŸ”œ Next Up
- [ ] Normalize and join datasets into community profiles
- [ ] Write `clean_transform.py`
- [ ] Create initial Quarto report with basic charts
- [ ] Set up database with schema.sql and db_utils.py

### âœ… Completed
- [x] Project scoped and canvas created
- [x] Project structure and tech stack defined
- [x] Quarto report starter scaffolded

## ğŸ”— Inspiration
This project draws from real-world questions faced by individuals and organizations: where to live, where to focus services, how communities are changing, and what economic conditions look like on the ground.
